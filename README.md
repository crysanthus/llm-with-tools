# llm-with-tools
The code demonstrates a practical example of how to inject user-defined functions into an LLM, allowing it to understand natural language queries and execute appropriate mathematical operations. The implementation uses Ollama, a powerful framework for running large language models locally.
